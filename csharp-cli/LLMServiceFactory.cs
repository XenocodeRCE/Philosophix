using System;
using System.IO;
using System.Text.Json;
using System.Threading.Tasks;

/// <summary>
/// Factory pour cr√©er le service LLM appropri√© selon la configuration
/// </summary>
public static class LLMServiceFactory
{
    /// <summary>
    /// Cr√©e une instance du service LLM configur√©
    /// </summary>
    /// <returns>Service LLM (OpenAI ou Ollama)</returns>
    public static ILLMService CreateService()
    {
        try
        {
            var config = LoadConfiguration();
            var provider = config.LLM?.Provider?.ToLower();

            switch (provider)
            {
                case "openai":
                    Console.WriteLine("üîß Configuration: Utilisation d'OpenAI");
                    return new OpenAiService();

                case "ollama":
                    Console.WriteLine("üîß Configuration: Utilisation d'Ollama (local)");
                    return new OllamaService();

                default:
                    Console.WriteLine($"‚ö†Ô∏è  Provider '{provider}' non reconnu, utilisation d'OpenAI par d√©faut");
                    return new OpenAiService();
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Erreur lors de la cr√©ation du service LLM : {ex.Message}");
            Console.WriteLine("üìã V√©rifiez votre configuration dans appsettings.json");
            throw;
        }
    }

    /// <summary>
    /// Affiche des informations sur la configuration LLM active
    /// </summary>
    public static void AfficherInfoConfiguration()
    {
        try
        {
            var config = LoadConfiguration();
            var provider = config.LLM?.Provider ?? "OpenAI";

            Console.WriteLine("\n" + new string('‚ïê', 50));
            Console.WriteLine("ü§ñ CONFIGURATION LLM ACTIVE");
            Console.WriteLine(new string('‚ïê', 50));
            Console.WriteLine($"Provider : {provider}");

            if (provider.ToLower() == "openai")
            {
                Console.WriteLine($"Mod√®le : {config.OpenAI?.Model ?? "gpt-4o-mini"}");
                Console.WriteLine($"Max Tokens : {config.OpenAI?.MaxTokens ?? 8000}");
                Console.WriteLine($"Temp√©rature : {config.OpenAI?.Temperature ?? 1.0}");
                Console.WriteLine("üí∞ Co√ªt : Payant (suivi automatique)");
            }
            else if (provider.ToLower() == "ollama")
            {
                Console.WriteLine($"Mod√®le : {config.Ollama?.Model ?? "llama3.1:8b"}");
                Console.WriteLine($"URL : {config.Ollama?.BaseUrl ?? "http://localhost:11434"}");
                Console.WriteLine($"Temp√©rature : {config.Ollama?.Temperature ?? 1.0}");
                Console.WriteLine("üÜì Co√ªt : Gratuit (local)");
            }

            Console.WriteLine(new string('‚ïê', 50));
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ö†Ô∏è  Impossible d'afficher la configuration : {ex.Message}");
        }
    }

    /// <summary>
    /// V√©rifie si Ollama est accessible si configur√©
    /// </summary>
    public static async Task<bool> VerifierConnexionOllamaAsync()
    {
        try
        {
            var config = LoadConfiguration();
            if (config.LLM?.Provider?.ToLower() == "ollama")
            {
                var ollamaService = new OllamaService();
                // Test simple de connexion
                await ollamaService.AskAsync("Tu es un assistant.", "Dis juste 'OK' pour tester la connexion.", "Test connexion");
                return true;
            }
            return true; // OpenAI ou autre provider
        }
        catch
        {
            return false;
        }
    }

    private static AppSettings LoadConfiguration()
    {
        var configPath = "appsettings.json";
        if (!File.Exists(configPath))
        {
            throw new FileNotFoundException($"Le fichier {configPath} est introuvable.");
        }

        var jsonContent = File.ReadAllText(configPath);
        var config = JsonSerializer.Deserialize<AppSettings>(jsonContent, new JsonSerializerOptions
        {
            PropertyNameCaseInsensitive = true
        });

        return config ?? throw new InvalidOperationException("Impossible de d√©s√©rialiser la configuration.");
    }
}

/// <summary>
/// Configuration √©tendue pour supporter le choix de provider
/// </summary>
public class LLMSettings
{
    public string Provider { get; set; } = "OpenAI";
}
